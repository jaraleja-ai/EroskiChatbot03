# =====================================================
# interfaces/chainlit_app.py - AplicaciÃ³n Chainlit con interrupciones
# =====================================================
"""
AplicaciÃ³n Chainlit refactorizada con sistema de interrupciones.

Cambios principales:
- Usa graph.invoke() en lugar de astream()
- Maneja interrupciones automÃ¡ticas en __interrupt__
- Sistema de continuaciÃ³n de flujos interrumpidos
- Estado persistente entre interrupciones
"""

import asyncio
import json
from datetime import datetime
from typing import Dict, Any, Optional, List
import logging

import chainlit as cl
from langchain_core.messages import HumanMessage, AIMessage


# Importaciones de la nueva arquitectura
from config.settings import get_settings
from config.logging_config import setup_logging
from graph import build_adaptive_graph, get_graph_builder, get_graph_metrics
from utils.crear_estado_inicial import (
    crear_estado_inicial, crear_estado_desde_mensaje, 
    obtener_resumen_estado, validar_integridad_estado
)
from utils.database import init_database, close_database
from workflow import get_workflow_manager, WorkflowType

class ChatbotSession:
    """
    Gestiona una sesiÃ³n individual de chatbot con sistema de interrupciones.
    
    Responsabilidades:
    - Mantener estado de la conversaciÃ³n
    - Ejecutar workflows con interrupciones
    - Manejar continuaciones de flujos interrumpidos
    - Gestionar debugging y mÃ©tricas
    """
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.thread_id = f"thread_{session_id}"  # ID del hilo para interrupciones
        self.logger = logging.getLogger(f"Session.{session_id[:8]}")
        self.settings = get_settings()
        
        # âœ… CONFIGURACIÃ“N DE ESTADO PERSISTENTE
        self.config = {
            "configurable": {"thread_id": self.thread_id},
            "recursion_limit": 100  # LÃ­mite de recursiÃ³n
        }
        
        # Estado de la sesiÃ³n
        self.graph_state = None
        self.current_graph = None
        self.is_processing = False
        self.conversation_complete = False
        self.is_interrupted = False
        self.pending_user_input = False
        
        # âœ… NUEVO: Estado de usuario persistente
        self.user_data = {
            "nombre": None,
            "email": None,
            "numero_empleado": None,
            "nombre_confirmado": False,
            "email_confirmado": False,
            "datos_usuario_completos": False
        }
        
        # MÃ©tricas de la sesiÃ³n
        self.start_time = datetime.now()
        self.message_count = 0
        self.error_count = 0
        self.interruption_count = 0
        
        self.logger.info(f"ğŸ†• Nueva sesiÃ³n iniciada: {session_id}")
    

    # âœ… NUEVO MÃ‰TODO - Preservar datos de usuario
    def _preserve_user_data_in_state(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        Preservar datos de usuario en el estado entre ejecuciones.
        
        Args:
            state: Estado actual
            
        Returns:
            Estado con datos de usuario preservados
        """
        # Preservar datos existentes
        for key, value in self.user_data.items():
            if value is not None:
                state[key] = value
                self.logger.debug(f"ğŸ”„ Preservando {key}: {value}")
        
        return state

    # âœ… NUEVO MÃ‰TODO - Extraer y guardar datos de usuario
    def _extract_and_save_user_data(self, state: Dict[str, Any]):
        """
        Extraer y guardar datos de usuario del estado.
        
        Args:
            state: Estado del grafo
        """
        user_fields = ["nombre", "email", "numero_empleado", 
                      "nombre_confirmado", "email_confirmado", "datos_usuario_completos"]
        
        for field in user_fields:
            if field in state and state[field] is not None:
                old_value = self.user_data.get(field)
                new_value = state[field]
                
                if old_value != new_value:
                    self.user_data[field] = new_value
                    self.logger.info(f"ğŸ’¾ Guardando {field}: {old_value} â†’ {new_value}")
    
    # âœ… NUEVO MÃ‰TODO - Extraer mensajes AI nuevos  
    def _extract_new_ai_messages(self, all_messages: List) -> List[AIMessage]:  # âœ… Retorna AIMessage
        """Extraer solo los mensajes AI nuevos desde el Ãºltimo mensaje del usuario"""
        try:
            from langchain_core.messages import HumanMessage, AIMessage
            
            # Encontrar el Ã­ndice del Ãºltimo mensaje humano
            last_human_idx = -1
            for i in range(len(all_messages) - 1, -1, -1):
                if isinstance(all_messages[i], HumanMessage):
                    last_human_idx = i
                    break
            
            # Obtener mensajes AI despuÃ©s del Ãºltimo mensaje humano
            if last_human_idx >= 0:
                new_messages = all_messages[last_human_idx + 1:]
                return [msg for msg in new_messages if isinstance(msg, AIMessage)]  # âœ… Retorna AIMessage objects
            else:
                # Si no hay mensajes humanos, devolver todos los AI
                return [msg for msg in all_messages if isinstance(msg, AIMessage)]
                
        except Exception as e:
            self.logger.error(f"âŒ Error extrayendo mensajes AI nuevos: {e}")
            return []

    async def initialize(self):
        """Inicializar la sesiÃ³n"""
        try:
            self.logger.info("ğŸ”§ Inicializando sesiÃ³n...")
            
            # Crear estado inicial
            self.graph_state = crear_estado_inicial(sesion_id=self.session_id)
            
            # Validar estado
            errores = validar_integridad_estado(self.graph_state)
            if errores:
                raise ValueError(f"Estado inicial invÃ¡lido: {errores}")
            
            self.logger.info("âœ… SesiÃ³n inicializada correctamente")
            
        except Exception as e:
            self.logger.error(f"âŒ Error inicializando sesiÃ³n: {e}")
            raise
    
    async def process_user_message(self, message: str) -> List[str]:
        """
        Procesar mensaje del usuario con sistema de interrupciones.
        
        Args:
            message: Mensaje del usuario
            
        Returns:
            Lista de respuestas del asistente
        """
        if self.is_processing:
            self.logger.warning("âš ï¸ Mensaje recibido mientras se procesa otro")
            return ["Un momento, estoy procesando tu mensaje anterior..."]
        
        self.is_processing = True
        self.message_count += 1
        
        try:
            self.logger.info(f"ğŸ“© Procesando mensaje #{self.message_count}: {message[:50]}...")
            
            # âœ… PRESERVAR DATOS DE USUARIO EN EL ESTADO
            if self.graph_state:
                self.graph_state = self._preserve_user_data_in_state(self.graph_state)
            
            # Agregar mensaje del usuario al estado
            user_message = HumanMessage(content=message)
            current_messages = self.graph_state.get("messages", [])
            self.graph_state["messages"] = current_messages + [user_message]
            
            # Si hay una interrupciÃ³n pendiente, continuar el flujo
            if self.is_interrupted and self.pending_user_input:
                responses = await self._continue_interrupted_flow()
            else:
                # Iniciar nuevo flujo
                responses = await self._start_new_flow()
            
            self.logger.info(f"âœ… Mensaje procesado - {len(responses)} respuestas generadas")
            return responses
            
        except Exception as e:
            self.error_count += 1
            self.logger.error(f"âŒ Error procesando mensaje: {e}", exc_info=True)
            return [f"Ha ocurrido un error. Por favor, intenta de nuevo. (Error #{self.error_count})"]
        
        finally:
            self.is_processing = False
    
    async def _start_new_flow(self) -> List[str]:
        """Iniciar un nuevo flujo de conversaciÃ³n"""
        try:
            # Seleccionar y compilar grafo apropiado si no existe
            if not self.current_graph:
                self.current_graph = build_adaptive_graph(self.graph_state)
                self.logger.info("ğŸ”§ Grafo adaptativo compilado")
            
            # Reset de estado de interrupciÃ³n
            self.is_interrupted = False
            self.pending_user_input = False
            
            # Ejecutar grafo con invoke (se detiene automÃ¡ticamente en interrupciones)
            return await self._execute_graph_invoke()
            
        except Exception as e:
            self.logger.error(f"âŒ Error iniciando nuevo flujo: {e}")
            raise
    
    # âœ… MODIFICAR MÃ‰TODO EXISTENTE
    async def _continue_interrupted_flow(self) -> List[str]:
        """Continuar un flujo que fue interrumpido"""
        try:
            self.logger.info("ğŸ”„ Continuando flujo interrumpido...")
            
            # âœ… PRESERVAR DATOS ANTES DE CONTINUAR
            if self.graph_state:
                self.graph_state = self._preserve_user_data_in_state(self.graph_state)
            
            # Marcar que ya no estamos esperando input
            self.pending_user_input = False
            
            # âœ… CONTINUAR CON CONFIGURACIÃ“N PERSISTENTE (SIN ESTADO INICIAL)
            result = await self.current_graph.ainvoke(
                None,  # âœ… NO pasar estado, usar el persistido
                config=self.config
            )
            
            # âœ… EXTRAER Y GUARDAR DATOS
            self._extract_and_save_user_data(result)
            
            # Procesar resultado
            return await self._process_graph_result(result)
            
        except Exception as e:
            self.logger.error(f"âŒ Error continuando flujo interrumpido: {e}")
            raise
    # âœ… MODIFICAR MÃ‰TODO EXISTENTE
    async def _execute_graph_invoke(self) -> List[str]:
        """
        Ejecutar grafo usando ainvoke con configuraciÃ³n persistente.
        """
        responses = []
        
        try:
            self.logger.info("ğŸš€ Ejecutando grafo con ainvoke...")
            
            # âœ… PRESERVAR DATOS ANTES DE EJECUTAR
            if self.graph_state:
                self.graph_state = self._preserve_user_data_in_state(self.graph_state)
            
            # âœ… EJECUTAR CON CONFIGURACIÃ“N PERSISTENTE
            result = await self.current_graph.ainvoke(
                self.graph_state, 
                config=self.config  # âœ… USAR CONFIG CON THREAD_ID
            )
            
            # âœ… EXTRAER Y GUARDAR DATOS DE USUARIO
            self._extract_and_save_user_data(result)
            
            # Verificar si el resultado indica una interrupciÃ³n
            if self._is_interrupted_result(result):
                self.logger.info("â¸ï¸ Flujo interrumpido - esperando input del usuario")
                self.is_interrupted = True
                self.pending_user_input = True
                self.interruption_count += 1
                
                # Obtener mensajes hasta el punto de interrupciÃ³n
                responses = await self._extract_messages_before_interruption(result.get("messages", []))
                return responses
            
            # Procesar resultado normal
            responses = await self._process_graph_result(result)
            
            return responses
            
        except Exception as e:
            self.logger.error(f"âŒ Error en ejecuciÃ³n del grafo: {e}")
            raise
    
    async def _process_graph_result(self, result: Dict[str, Any]) -> List[str]:
        """Procesar el resultado completo del grafo"""
        responses = []
        
        try:
            self.logger.info("ğŸ“¦ Procesando resultado del grafo")
            
            if not isinstance(result, dict):
                self.logger.warning(f"âš ï¸ Resultado no es dict: {type(result)}")
                return responses
            
            # Actualizar estado con el resultado
            self.graph_state.update(result)
            
            # Extraer mensajes AI para mostrar al usuario
            if "messages" in result:
                messages = result["messages"]
                # Obtener solo los mensajes nuevos (desde el Ãºltimo mensaje del usuario)
                new_messages = self._extract_new_ai_messages(messages)
                
                for msg in new_messages:
                    if isinstance(msg, AIMessage) and msg.content.strip():
                        responses.append(msg.content)
                        self.logger.debug(f"ğŸ’¬ Respuesta extraÃ­da: {msg.content[:50]}...")
            
            # Verificar estado de finalizaciÃ³n
            self._check_flow_completion(result)
            
            return responses
            
        except Exception as e:
            self.logger.error(f"âŒ Error procesando resultado del grafo: {e}")
            return []
    
    def _is_interrupted_result(self, result: Dict[str, Any]) -> bool:
        """
        Verificar si el resultado indica una interrupciÃ³n.
        
        En LangGraph, las interrupciones se detectan por:
        1. Estado especÃ­fico que indica necesidad de input
        2. Flags en el resultado
        3. Estado incompleto del flujo
        """
        try:
            # Verificar flags explÃ­citos de interrupciÃ³n
            if result.get("_interrupted", False):
                return True
            
            if result.get("requires_user_input", False):
                return True
            
            # Verificar si hay preguntas pendientes para el usuario
            if result.get("pending_questions"):
                return True
            
            # Verificar estado del workflow que indica interrupciÃ³n
            workflow_state = result.get("workflow_state", {})
            if workflow_state.get("waiting_for_user", False):
                return True
            
            # Verificar si el flujo no estÃ¡ completo y no hay prÃ³ximo nodo
            if not result.get("flujo_completado", False) and not result.get("next_node"):
                return True
            
            return False
            
        except Exception as e:
            self.logger.error(f"âŒ Error verificando interrupciÃ³n: {e}")
            return False

            
        except Exception as e:
            self.logger.error(f"âŒ Error extrayendo mensajes antes de interrupciÃ³n: {e}")
            return ["Hubo un problema procesando tu solicitud. Â¿Puedes proporcionar mÃ¡s detalles?"]
    
    async def _extract_messages_before_interruption(self, all_messages: List) -> List[str]:
        """Extraer mensajes generados antes de la interrupciÃ³n"""
        responses = []
        
        try:
            # Usar directamente los mensajes pasados como parÃ¡metro
            new_messages = self._extract_new_ai_messages(all_messages)
            
            for msg in new_messages:
                if isinstance(msg, AIMessage) and msg.content.strip():
                    responses.append(msg.content)  # âœ… Agregar msg.content (string), no msg (objeto)
            
            # Agregar mensaje indicando que se necesita mÃ¡s informaciÃ³n
            if not responses:
                responses.append("Necesito mÃ¡s informaciÃ³n para continuar. Â¿Puedes proporcionÃ¡rmela?")
            
            return responses  # âœ… Lista de strings
            
        except Exception as e:
            self.logger.error(f"âŒ Error extrayendo mensajes antes de interrupciÃ³n: {e}")
            return ["Hubo un problema procesando tu solicitud. Â¿Puedes proporcionar mÃ¡s detalles?"]
    
    def _check_flow_completion(self, result: Dict[str, Any]):
        """Verificar si el flujo ha terminado"""
        self.conversation_complete = (
            result.get("flujo_completado", False) or
            result.get("escalar_a_supervisor", False) or
            result.get("incidencia_resuelta", False)
        )
        
        if self.conversation_complete:
            self.logger.info("ğŸ Flujo completado")
            self.is_interrupted = False
            self.pending_user_input = False
    
    def get_session_summary(self) -> Dict[str, Any]:
        """Obtener resumen de la sesiÃ³n"""
        duration = (datetime.now() - self.start_time).total_seconds()
        
        return {
            "session_id": self.session_id,
            "thread_id": self.thread_id,
            "duration_seconds": duration,
            "message_count": self.message_count,
            "error_count": self.error_count,
            "interruption_count": self.interruption_count,
            "is_interrupted": self.is_interrupted,
            "pending_user_input": self.pending_user_input,
            "conversation_complete": self.conversation_complete,
            "state_summary": obtener_resumen_estado(self.graph_state) if self.graph_state else None
        }

class ChatbotManager:
    """
    Gestor principal del chatbot que coordina sesiones y configuraciÃ³n global.
    
    Responsabilidades:
    - Gestionar ciclo de vida de sesiones
    - Coordinar inicializaciÃ³n de servicios
    - Manejar debugging global
    - Proporcionar mÃ©tricas agregadas
    """
    
    def __init__(self):
        self.settings = get_settings()
        self.logger = logging.getLogger("ChatbotManager")
        self.sessions: Dict[str, ChatbotSession] = {}
        self.debug_mode = self.settings.app.debug_mode
        
        # EstadÃ­sticas globales
        self.total_sessions = 0
        self.total_messages = 0
        self.total_interruptions = 0  # Nuevo: contador global de interrupciones
        
    async def initialize_services(self):
        """Inicializar servicios globales del chatbot"""
        try:
            self.logger.info("ğŸš€ Inicializando servicios del chatbot...")
            
            # Configurar logging
            setup_logging()
            
            # Inicializar base de datos
            self.logger.info("ğŸ—„ï¸ Inicializando conexiÃ³n a base de datos...")
            await init_database()
            
            # Verificar workflows
            workflow_manager = get_workflow_manager()
            workflows = workflow_manager.list_workflows()
            self.logger.info(f"ğŸ”§ Workflows disponibles: {workflows}")
            
            # Verificar configuraciÃ³n
            from config.settings import validate_environment
            if not validate_environment():
                raise RuntimeError("ConfiguraciÃ³n del entorno invÃ¡lida")
            
            self.logger.info("âœ… Servicios inicializados correctamente")
            
        except Exception as e:
            self.logger.error(f"âŒ Error inicializando servicios: {e}")
            raise
    
    async def create_session(self, session_id: str) -> ChatbotSession:
        """Crear nueva sesiÃ³n de chatbot"""
        try:
            self.logger.info(f"ğŸ†• Creando nueva sesiÃ³n: {session_id}")
            
            session = ChatbotSession(session_id)
            await session.initialize()
            
            self.sessions[session_id] = session
            self.total_sessions += 1
            
            self.logger.info(f"âœ… SesiÃ³n creada exitosamente: {session_id}")
            return session
            
        except Exception as e:
            self.logger.error(f"âŒ Error creando sesiÃ³n {session_id}: {e}")
            raise
    
    def get_session(self, session_id: str) -> Optional[ChatbotSession]:
        """Obtener sesiÃ³n existente"""
        return self.sessions.get(session_id)
    
    async def cleanup_session(self, session_id: str):
        """Limpiar sesiÃ³n terminada"""
        if session_id in self.sessions:
            session = self.sessions[session_id]
            summary = session.get_session_summary()
            
            # Actualizar estadÃ­sticas globales
            self.total_interruptions += summary.get("interruption_count", 0)
            
            self.logger.info(f"ğŸ§¹ Limpiando sesiÃ³n {session_id}")
            self.logger.debug(f"ğŸ“Š Resumen: {summary}")
            
            del self.sessions[session_id]
    
    async def cleanup_services(self):
        """Cleanup de servicios globales"""
        try:
            self.logger.info("ğŸ§¹ Limpiando servicios...")
            
            # Limpiar todas las sesiones
            for session_id in list(self.sessions.keys()):
                await self.cleanup_session(session_id)
            
            # Cerrar conexiones de BD
            await close_database()
            
            self.logger.info("âœ… Servicios limpiados")
            
        except Exception as e:
            self.logger.error(f"âŒ Error en cleanup: {e}")
    
    async def handle_debug_command(self, command: str, session_id: str) -> str:
        """Manejar comandos de debug"""
        if not self.debug_mode:
            return "ğŸ› Debug mode no estÃ¡ activado"
        
        try:
            parts = command.split()
            cmd = parts[1] if len(parts) > 1 else ""
            
            if cmd == "state":
                session = self.get_session(session_id)
                if session and session.graph_state:
                    resumen = obtener_resumen_estado(session.graph_state)
                    interruption_info = {
                        "is_interrupted": session.is_interrupted,
                        "pending_user_input": session.pending_user_input,
                        "interruption_count": session.interruption_count
                    }
                    resumen["interruption_status"] = interruption_info
                    return f"```json\n{json.dumps(resumen, indent=2, default=str)}\n```"
                return "âŒ No hay sesiÃ³n activa"
            
            elif cmd == "metrics":
                metrics = get_graph_metrics()
                global_metrics = {
                    "total_sessions": self.total_sessions,
                    "total_interruptions": self.total_interruptions,
                    "active_sessions": len(self.sessions)
                }
                metrics["global_stats"] = global_metrics
                return f"```json\n{json.dumps(metrics, indent=2, default=str)}\n```"
            
            elif cmd == "sessions":
                sessions_info = {
                    "total_sessions": self.total_sessions,
                    "active_sessions": len(self.sessions),
                    "total_interruptions": self.total_interruptions,
                    "session_details": {}
                }
                
                for sid, session in self.sessions.items():
                    sessions_info["session_details"][sid] = {
                        "is_interrupted": session.is_interrupted,
                        "pending_user_input": session.pending_user_input,
                        "interruption_count": session.interruption_count,
                        "message_count": session.message_count
                    }
                
                return f"```json\n{json.dumps(sessions_info, indent=2)}\n```"
            
            elif cmd == "continue":
                session = self.get_session(session_id)
                if session and session.is_interrupted:
                    # Forzar continuaciÃ³n del flujo interrumpido
                    session.pending_user_input = False
                    return "ğŸ”„ Flujo interrumpido serÃ¡ continuado en el prÃ³ximo mensaje"
                return "âŒ No hay flujo interrumpido para continuar"
            
            elif cmd == "reset":
                session = self.get_session(session_id)
                if session:
                    await session.initialize()
                    return "ğŸ”„ SesiÃ³n reiniciada"
                return "âŒ No hay sesiÃ³n para reiniciar"
            
            elif cmd == "off":
                self.debug_mode = False
                return "ğŸ› Debug mode desactivado"
            
            else:
                return """ğŸ› **Comandos de debug disponibles:**
- `/debug state` - Ver estado actual e info de interrupciones
- `/debug metrics` - Ver mÃ©tricas del sistema
- `/debug sessions` - Ver informaciÃ³n de sesiones
- `/debug continue` - Forzar continuaciÃ³n de flujo interrumpido
- `/debug reset` - Reiniciar sesiÃ³n actual
- `/debug off` - Desactivar debug mode"""
        
        except Exception as e:
            return f"âŒ Error en comando debug: {e}"

# Instancia global del manager
chatbot_manager = ChatbotManager()

# =====================================================
# EVENTOS DE CHAINLIT (sin cambios significativos)
# =====================================================

@cl.on_chat_start
async def start():
    """Inicializar cuando se inicia el chat"""
    session_id = cl.user_session.get("id", f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
    
    try:
        # Inicializar servicios si es necesario
        if not chatbot_manager.sessions:
            await chatbot_manager.initialize_services()
        
        # Crear sesiÃ³n
        session = await chatbot_manager.create_session(session_id)
        
        # Guardar en sesiÃ³n de Chainlit
        cl.user_session.set("chatbot_session", session)
        
        # Mensaje de bienvenida
        welcome_message = "Â¡Hola! Soy tu **Asistente de Incidencias** ğŸ› ï¸\n\n"
        welcome_message += "Estoy aquÃ­ para ayudarte con cualquier problema tÃ©cnico que tengas. "
        welcome_message += "Â¿En quÃ© puedo asistirte hoy?"
        
        if chatbot_manager.debug_mode:
            welcome_message += f"\n\nğŸ› **Debug Mode Activado** (SesiÃ³n: {session_id[:8]})\n"
            welcome_message += "**Sistema de interrupciones habilitado**\n"
            welcome_message += "Comandos: `/debug state`, `/debug metrics`, `/debug continue`, `/debug reset`, `/debug off`"
        
        await cl.Message(
            content=welcome_message,
            author="Asistente"
        ).send()
        
        session.logger.info("âœ… Chat iniciado correctamente")
        
    except Exception as e:
        error_msg = f"âŒ Error al inicializar el asistente: {str(e)}"
        await cl.Message(content=error_msg, author="Sistema").send()
        
        if hasattr(chatbot_manager, 'logger'):
            chatbot_manager.logger.error(f"âŒ Error en inicio de chat: {e}")

@cl.on_message
async def main(message: cl.Message):
    """Manejar mensajes del usuario con soporte para interrupciones"""
    user_input = message.content.strip()
    
    # Obtener sesiÃ³n
    session: ChatbotSession = cl.user_session.get("chatbot_session")
    if not session:
        await cl.Message(
            content="âŒ Error: SesiÃ³n no encontrada. Por favor, recarga la pÃ¡gina.",
            author="Sistema"
        ).send()
        return
    
    try:
        session.logger.info(f"ğŸ“¨ Mensaje recibido: {user_input[:50]}...")
        
        # Manejar comandos de debug
        if user_input.startswith("/debug"):
            debug_response = await chatbot_manager.handle_debug_command(user_input, session.session_id)
            await cl.Message(content=debug_response, author="Debug").send()
            return
        
        # Mostrar indicador de carga apropiado
        if session.is_interrupted and session.pending_user_input:
            loading_msg = cl.Message(content="ğŸ”„ Continuando el proceso...", author="Asistente")
        else:
            loading_msg = cl.Message(content="ğŸ¤” Procesando tu mensaje...", author="Asistente")
        
        await loading_msg.send()
        
        try:
            # Procesar mensaje
            responses = await session.process_user_message(user_input)
            
            # Remover indicador de carga
            await loading_msg.remove()
            
            # Enviar respuestas
            for i, response in enumerate(responses):
                if response.strip():  # Solo enviar respuestas no vacÃ­as
                    await cl.Message(
                        content=response,
                        author="Asistente"
                    ).send()
                    
                    # PequeÃ±a pausa entre mensajes mÃºltiples
                    if i < len(responses) - 1:
                        await asyncio.sleep(0.5)
            
            # Mostrar estado de interrupciÃ³n en debug mode
            if chatbot_manager.debug_mode and session.is_interrupted:
                debug_info = f"â¸ï¸ **Flujo interrumpido** - Esperando tu respuesta\n"
                debug_info += f"Interrupciones en esta sesiÃ³n: {session.interruption_count}"
                
                await cl.Message(
                    content=debug_info,
                    author="Debug"
                ).send()
            
            # Verificar si la conversaciÃ³n ha terminado
            if session.conversation_complete:
                session.logger.info("ğŸ ConversaciÃ³n completada")
                
                # Mensaje de finalizaciÃ³n
                if not session.graph_state.get("escalar_a_supervisor", False):
                    await asyncio.sleep(1)
                    await cl.Message(
                        content="âœ¨ **Â¿Hay algo mÃ¡s en lo que pueda ayudarte?**\n\nSi tienes otra consulta, simplemente escrÃ­bela.",
                        author="Asistente"
                    ).send()
        
        except Exception as e:
            # Remover indicador de carga en caso de error
            try:
                await loading_msg.remove()
            except:
                pass
            
            session.logger.error(f"âŒ Error procesando mensaje: {e}", exc_info=True)
            
            error_message = "âŒ Ha ocurrido un error procesando tu mensaje. "
            if chatbot_manager.debug_mode:
                error_message += f"Detalles: {str(e)}"
            else:
                error_message += "Por favor, intenta de nuevo o contacta a soporte si persiste."
            
            await cl.Message(content=error_message, author="Sistema").send()
        
    except Exception as e:
        # Error crÃ­tico
        await cl.Message(
            content=f"ğŸ’¥ Error crÃ­tico: {str(e)}. Por favor, recarga la pÃ¡gina.",
            author="Sistema"
        ).send()
        
        if hasattr(session, 'logger'):
            session.logger.error(f"ğŸ’¥ Error crÃ­tico en main: {e}", exc_info=True)

@cl.on_stop
async def stop():
    """Cleanup cuando se detiene el chat"""
    session: ChatbotSession = cl.user_session.get("chatbot_session")
    
    if session:
        session.logger.info("ğŸ›‘ Chat detenido por el usuario")
        
        # Obtener resumen final
        summary = session.get_session_summary()
        session.logger.info(f"ğŸ“Š Resumen final: {summary}")
        
        # Cleanup de la sesiÃ³n
        await chatbot_manager.cleanup_session(session.session_id)
    
    # Si no hay mÃ¡s sesiones activas, cleanup de servicios
    if not chatbot_manager.sessions:
        await chatbot_manager.cleanup_services()

# =====================================================
# CONFIGURACIÃ“N DE CHAINLIT (sin cambios)
# =====================================================

@cl.set_starters
async def set_starters():
    """Configurar mensajes de inicio sugeridos"""
    settings = get_settings()
    
    starters = [
        cl.Starter(
            label="ğŸ–¥ï¸ Problema con mi computadora",
            message="Hola, tengo un problema con mi computadora. Se estÃ¡ ejecutando muy lenta.",
            icon="/public/computer.svg",
        ),
        cl.Starter(
            label="ğŸ“§ Problemas con email",
            message="No puedo acceder a mi correo electrÃ³nico corporativo.",
            icon="/public/email.svg",
        ),
        cl.Starter(
            label="ğŸŒ ConexiÃ³n a internet",
            message="Tengo problemas de conexiÃ³n a internet en mi Ã¡rea de trabajo.",
            icon="/public/wifi.svg",
        ),
        cl.Starter(
            label="ğŸ”’ Olvide mi contraseÃ±a",
            message="He olvidado mi contraseÃ±a y no puedo acceder al sistema.",
            icon="/public/lock.svg",
        )
    ]
    
    return starters

@cl.set_chat_profiles
async def chat_profile():
    """Configurar perfiles de chat"""
    return [
        cl.ChatProfile(
            name="incidencias",
            markdown_description="Asistente para **incidencias tÃ©cnicas** completo con escalaciÃ³n automÃ¡tica.",
            icon="ğŸ› ï¸",
        ),
        cl.ChatProfile(
            name="consultas",
            markdown_description="Asistente para **consultas rÃ¡pidas** e informaciÃ³n general.",
            icon="â“",
        ),
    ]

# =====================================================
# FUNCIÃ“N PARA EJECUTAR LA APLICACIÃ“N
# =====================================================

async def run_chainlit_app():
    """
    FunciÃ³n para ejecutar la aplicaciÃ³n Chainlit.
    Usada por el entry point principal.
    """
    try:
        chatbot_manager.logger.info("ğŸš€ AplicaciÃ³n Chainlit con interrupciones lista para ejecutar")
        return True
        
    except Exception as e:
        print(f"âŒ Error configurando aplicaciÃ³n Chainlit: {e}")
        return False

# =====================================================
# CONFIGURACIÃ“N ADICIONAL
# =====================================================

try:
    import chainlit as cl
    
    if hasattr(cl, 'md') and hasattr(cl.md, 'ChatProfile'):
        cl.md.ChatProfile.markdown_description = """
# ğŸ¤– Asistente de Incidencias TÃ©cnicas (Sistema de Interrupciones)

Bienvenido al sistema inteligente de soporte tÃ©cnico con **sistema de interrupciones avanzado**. 

## âœ¨ Nuevas caracterÃ­sticas:

- **ğŸ”„ Interrupciones inteligentes** - El sistema se detiene automÃ¡ticamente cuando necesita mÃ¡s informaciÃ³n
- **ğŸ’¬ Conversaciones contextuales** - Mantiene el contexto entre interrupciones  
- **âš¡ Respuestas mÃ¡s precisas** - Hace preguntas especÃ­ficas para resolver mejor tu problema

## Â¿CÃ³mo funciona?

1. **CuÃ©ntame tu problema** - Describe quÃ© estÃ¡ pasando
2. **ConversaciÃ³n interactiva** - Te harÃ© preguntas especÃ­ficas durante el proceso
3. **ResoluciÃ³n dirigida** - Cada interrupciÃ³n nos acerca mÃ¡s a la soluciÃ³n
4. **Seguimiento personalizado** - Hasta que tu problema estÃ© completamente resuelto

Â¡Empecemos! Describe tu problema y experimentarÃ¡s un flujo mÃ¡s inteligente y dirigido ğŸš€
"""
    else:
        print("âš ï¸ API cl.md no disponible, usando configuraciÃ³n bÃ¡sica")
        
except Exception as e:
    print(f"âš ï¸ Error configurando perfil de chat: {e}")

if __name__ == "__main__":
    print("ğŸš€ Para ejecutar la aplicaciÃ³n Chainlit, usa: chainlit run interfaces/chainlit_app.py")
    print("ğŸ”§ O desde el directorio raÃ­z: python main.py")