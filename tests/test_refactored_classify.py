#!/usr/bin/env python3
"""
Test espec√≠fico para verificar que el nodo classify refactorizado funciona correctamente.
"""

import asyncio
import sys
from pathlib import Path

# Agregar el directorio ra√≠z al path
sys.path.insert(0, str(Path(__file__).parent))

def test_helpers_creation():
    """Probar que los helpers se crean correctamente"""
    
    print("üß™ Probando creaci√≥n de helpers...")
    
    try:
        from utils.incident_helpers import IncidentHelpersFactory
        
        # Crear helpers usando factory
        incident_types = {"balanza": {"name": "test", "problemas": {"test": "test solution"}}}
        incidents_file = Path("test_incidents.json")
        
        helpers = IncidentHelpersFactory.create_all_helpers(incident_types, incidents_file)
        
        # Verificar que se crearon todos
        expected_helpers = ["code_manager", "solution_searcher", "confirmation_handler", "persistence_manager"]
        
        for helper_name in expected_helpers:
            if helper_name in helpers:
                print(f"‚úÖ {helper_name} creado correctamente")
            else:
                print(f"‚ùå {helper_name} NO creado")
                
        return True
        
    except Exception as e:
        print(f"‚ùå Error creando helpers: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_code_manager():
    """Probar el gestor de c√≥digos"""
    
    print("\nüß™ Probando IncidentCodeManager...")
    
    try:
        from utils.incident_helpers import IncidentCodeManager
        
        # Crear gestor con archivo temporal
        test_file = Path("test_incidents.json")
        code_manager = IncidentCodeManager(test_file)
        
        # Generar c√≥digos
        code1 = code_manager.generate_unique_code()
        code2 = code_manager.generate_unique_code()
        
        print(f"‚úÖ C√≥digo 1: {code1}")
        print(f"‚úÖ C√≥digo 2: {code2}")
        
        # Verificar formato
        if code_manager.validate_code_format(code1):
            print(f"‚úÖ Formato v√°lido para {code1}")
        else:
            print(f"‚ùå Formato inv√°lido para {code1}")
        
        # Verificar que son diferentes
        if code1 != code2:
            print("‚úÖ C√≥digos √∫nicos generados")
        else:
            print("‚ùå C√≥digos duplicados")
            
        # Limpiar archivo de prueba
        if test_file.exists():
            test_file.unlink()
            
        return True
        
    except Exception as e:
        print(f"‚ùå Error en CodeManager: {e}")
        return False

def test_solution_searcher():
    """Probar el buscador de soluciones"""
    
    print("\nüß™ Probando SolutionSearcher...")
    
    try:
        from utils.incident_helpers import SolutionSearcher
        
        # Crear datos de prueba
        incident_types = {
            "balanza": {
                "name": "Balanzas",
                "problemas": {
                    "La balanza no imprime etiquetas": "Verificar papel y reiniciar",
                    "La balanza no enciende": "Verificar conexi√≥n el√©ctrica"
                }
            }
        }
        
        searcher = SolutionSearcher(incident_types)
        
        # Probar b√∫squeda
        problem, solution = searcher.find_best_solution("balanza", "no imprime etiquetas")
        
        if problem and solution:
            print(f"‚úÖ Soluci√≥n encontrada:")
            print(f"   Problema: {problem}")
            print(f"   Soluci√≥n: {solution}")
        else:
            print("‚ùå No se encontr√≥ soluci√≥n")
        
        # Probar formateo de preguntas
        questions = searcher.format_problems_for_user("balanza")
        print(f"‚úÖ Preguntas generadas:")
        print(f"   {questions[:100]}...")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error en SolutionSearcher: {e}")
        return False

async def test_confirmation_handler():
    """Probar el manejador de confirmaciones"""
    
    print("\nüß™ Probando ConfirmationLLMHandler...")
    
    try:
        from utils.incident_helpers import ConfirmationLLMHandler
        from models.eroski_state import EroskiState
        from datetime import datetime
        
        handler = ConfirmationLLMHandler()
        
        # Crear estado de prueba
        state = {
            "auth_data_collected": {
                "name": "Test User",
                "store_name": "Test Store",
                "section": "Test Section"
            }
        }
        
        # Probar interpretaci√≥n (esto requiere LLM real)
        print("‚ö†Ô∏è Test de confirmaci√≥n requiere LLM - simulando...")
        
        # Simular respuesta
        print("‚úÖ ConfirmationLLMHandler inicializado correctamente")
        print("üí° Test completo requiere LLM conectado")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error en ConfirmationHandler: {e}")
        return False

def test_persistence_manager():
    """Probar el gestor de persistencia"""
    
    print("\nüß™ Probando IncidentPersistence...")
    
    try:
        from utils.incident_helpers import IncidentPersistence
        from models.eroski_state import EroskiState
        from langchain_core.messages import HumanMessage, AIMessage
        
        # Crear gestor con archivo temporal
        test_file = Path("test_persistence.json")
        persistence = IncidentPersistence(test_file)
        
        # Crear estado de prueba
        state = {
            "auth_data_collected": {
                "name": "Test User",
                "email": "test@eroski.es",
                "store_name": "Test Store",
                "section": "Test Section"
            },
            "messages": [
                HumanMessage(content="Test message"),
                AIMessage(content="Test response")
            ]
        }
        
        # Probar inicializaci√≥n
        success = persistence.initialize_incident(state, "ER-1234")
        print(f"‚úÖ Inicializaci√≥n: {'exitosa' if success else 'fall√≥'}")
        
        # Probar actualizaci√≥n
        success = persistence.update_incident("ER-1234", {"tipo_incidencia": "test"})
        print(f"‚úÖ Actualizaci√≥n: {'exitosa' if success else 'fall√≥'}")
        
        # Probar guardado de mensajes
        success = persistence.save_messages("ER-1234", state["messages"])
        print(f"‚úÖ Guardado mensajes: {'exitoso' if success else 'fall√≥'}")
        
        # Verificar archivo
        if test_file.exists():
            print("‚úÖ Archivo de persistencia creado")
            
            # Leer y mostrar contenido
            import json
            with open(test_file, 'r') as f:
                data = json.load(f)
                print(f"‚úÖ Incidencias en archivo: {len(data)}")
                
            # Limpiar
            test_file.unlink()
        else:
            print("‚ùå Archivo de persistencia NO creado")
            
        return True
        
    except Exception as e:
        print(f"‚ùå Error en Persistence: {e}")
        return False

async def test_refactored_node():
    """Probar el nodo refactorizado completo"""
    
    print("\nüß™ Probando nodo classify refactorizado...")
    
    try:
        from nodes.classify_llm_driven import LLMDrivenClassifyNode
        from models.eroski_state import EroskiState
        from langchain_core.messages import HumanMessage, AIMessage
        from datetime import datetime
        
        # Crear nodo
        node = LLMDrivenClassifyNode()
        
        print(f"‚úÖ Nodo creado")
        print(f"‚úÖ Helpers disponibles: {list(node.helpers.keys())}")
        print(f"‚úÖ Tipos de incidencia: {len(node.incident_types)}")
        
        # Verificar que los helpers est√°n correctamente asignados
        if hasattr(node, 'code_manager'):
            print("‚úÖ code_manager asignado")
        if hasattr(node, 'solution_searcher'):
            print("‚úÖ solution_searcher asignado")
        if hasattr(node, 'confirmation_handler'):
            print("‚úÖ confirmation_handler asignado")
        if hasattr(node, 'persistence_manager'):
            print("‚úÖ persistence_manager asignado")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error en nodo refactorizado: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """Ejecutar todos los tests"""
    
    print("üöÄ INICIANDO TESTS DE REFACTORIZACI√ìN")
    print("=" * 60)
    
    tests = [
        ("Creaci√≥n de Helpers", test_helpers_creation),
        ("Gestor de C√≥digos", test_code_manager),
        ("Buscador de Soluciones", test_solution_searcher),
        ("Manejador de Confirmaciones", test_confirmation_handler),
        ("Gestor de Persistencia", test_persistence_manager),
        ("Nodo Refactorizado", test_refactored_node)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        
        try:
            if asyncio.iscoroutinefunction(test_func):
                result = await test_func()
            else:
                result = test_func()
            results[test_name] = result
        except Exception as e:
            print(f"üí• Error en {test_name}: {e}")
            results[test_name] = False
    
    # Resumen
    print("\n" + "=" * 60)
    print("üìã RESUMEN DE TESTS:")
    
    passed = 0
    total = len(tests)
    
    for test_name, result in results.items():
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"  {status} {test_name}")
        if result:
            passed += 1
    
    print(f"\nüéØ Resultado: {passed}/{total} tests pasaron")
    
    if passed == total:
        print("üéâ ¬°Todos los tests de refactorizaci√≥n pasaron!")
        print("üí° El nodo classify est√° listo para usar con helpers especializados")
    else:
        print("‚ö†Ô∏è Algunos tests fallaron - revisar implementaci√≥n")

if __name__ == "__main__":
    asyncio.run(main())